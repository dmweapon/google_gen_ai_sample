{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1btZCldJxz-DFxshEjVFBksH3cFZ7ZWzY","timestamp":1717886695950}],"toc_visible":true,"authorship_tag":"ABX9TyOjPFyhwwhLjTM5EUMN3rtl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Disclaimer & Copyright\n","\n","Copyright 2024 Forusone : shins777@gmail.com\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n","\n","https://www.apache.org/licenses/LICENSE-2.0\n","\n","Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."],"metadata":{"id":"OQJknXG7C9Dq"}},{"cell_type":"markdown","source":["# Gemini - Youtube video analysis\n","* This notebook explains how to use Gemini to understand images in multimodality features of Gemini. This code shows how to use Gemini to analyze a Youtube videos with the feature.\n","* The youtube video that is used in this demo is \"https://www.youtube.com/watch?v=rwF-X5STYks\", the usage of the videos is just for the educational purpose.\n","* The video owner is KI Campus, please contact them to get permission if you want to use it.\n","* Don't use this Youtube video for the other purpose.\n","* Refer to the link for more information about the Gemini\n"," * ***https://cloud.google.com/vertex-ai/generative-ai/docs/learn/overview***"],"metadata":{"id":"zB93wBDYDCPI"}},{"cell_type":"markdown","source":["# Configuration\n","## Install python packages\n","* Vertex AI SDK for Python\n","  * https://cloud.google.com/python/docs/reference/aiplatform/latest\n","* Vertex AI initialization : aiplatform.init(..)\n","  * https://cloud.google.com/python/docs/reference/aiplatform/latest#initialization\n","* Install pytube to download the Youtube video\n","  * https://github.com/pytube/pytube\n","  * pip install pytube"],"metadata":{"id":"Vuxu3iRDDtcl"}},{"cell_type":"code","source":["%pip install --upgrade --quiet google-cloud-aiplatform"],"metadata":{"id":"wevZD-jnD-ft","executionInfo":{"status":"ok","timestamp":1718194542904,"user_tz":-540,"elapsed":12731,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["%pip install -q -U pytube"],"metadata":{"id":"481AaKRW__oz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718194557898,"user_tz":-540,"elapsed":14997,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"c03b82a0-79c3-459e-e794-6d108950e293"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["from IPython.display import display, Markdown"],"metadata":{"id":"-nhL4T2sKsdp","executionInfo":{"status":"ok","timestamp":1718194557899,"user_tz":-540,"elapsed":4,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Authentication to access to the GCP & Google drive\n","\n","* Use OAuth to access the GCP environment.\n"," * Refer to the authentication methods in GCP : https://cloud.google.com/docs/authentication?hl=ko"],"metadata":{"id":"tCVttGUsEzgj"}},{"cell_type":"code","source":["#  For only colab to authenticate to get an access to the GCP.\n","import sys\n","\n","if \"google.colab\" in sys.modules:\n","    from google.colab import auth\n","    auth.authenticate_user()"],"metadata":{"id":"AJuo1g4bE3-x","executionInfo":{"status":"ok","timestamp":1718194572046,"user_tz":-540,"elapsed":14151,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["* Mount to the google drive to access the .ipynb files in the repository.\n","\n"],"metadata":{"id":"mQoisCsVE6LM"}},{"cell_type":"code","source":["# To access contents in Google drive\n","\n","if \"google.colab\" in sys.modules:\n","  from google.colab import drive\n","  drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZhluEayrE_Io","executionInfo":{"status":"ok","timestamp":1718194979428,"user_tz":-540,"elapsed":18631,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"d00369d0-f7f3-4da9-a6a7-96a1f8d4a169"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Download the Youtube video to anlyze.\n","* The youtube video that is used in this demo is \"https://www.youtube.com/watch?v=rwF-X5STYks\", the usage of the videos is just for the educational purpose.\n","* The video owner is KI Campus, please contact them to get permission if you want to use it."],"metadata":{"id":"ktnOTtoJD2wx"}},{"cell_type":"code","source":["from pytube import YouTube\n","\n","# Download youtube video to your local drive in colab.\n","YouTube('https://www.youtube.com/watch?v=rwF-X5STYks').streams.first().download()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":39},"id":"SYt7U21d_zob","executionInfo":{"status":"ok","timestamp":1718194991294,"user_tz":-540,"elapsed":4086,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"c3dd7431-5c3d-4f32-a29d-ef41e04f6d10"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/Generative AI explained in 2 minutes.mp4'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["if \"google.colab\" in sys.modules:\n","\n","  import moviepy.editor\n","  moviepy.editor.ipython_display(\"Generative AI explained in 2 minutes.mp4\", maxduration = 130)"],"metadata":{"id":"b-OBKUvnHIJ2","executionInfo":{"status":"ok","timestamp":1718194992977,"user_tz":-540,"elapsed":1686,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# Execute the example\n","## Set the environment on GCP Project\n","* Configure project information\n","  * Model name : LLM model name : https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n","  * Project Id : prodect id in GCP\n","  * Region : region name in GCP"],"metadata":{"id":"ey_Bv55hIblt"}},{"cell_type":"code","source":["MODEL_NAME=\"gemini-1.5-flash\"\n","PROJECT_ID=\"ai-hangsik\"\n","REGION=\"asia-northeast3\""],"metadata":{"id":"XJwhurOUHIG-","executionInfo":{"status":"ok","timestamp":1718194992977,"user_tz":-540,"elapsed":3,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### Vertex AI initialization\n","Configure Vertex AI and access to the foundation model."],"metadata":{"id":"Xk3nZQQhIiom"}},{"cell_type":"code","source":["import vertexai\n","from vertexai.preview.generative_models import GenerativeModel, Part\n","import vertexai.preview.generative_models as generative_models\n","\n","# Initalizate the current vertex AI execution environment.\n","vertexai.init(project=PROJECT_ID, location=REGION)\n","\n","# Access to the generative model.\n","model = GenerativeModel(MODEL_NAME)"],"metadata":{"id":"HZ6WeWz4HIEW","executionInfo":{"status":"ok","timestamp":1718194997965,"user_tz":-540,"elapsed":4990,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["Encoding function for multimodality"],"metadata":{"id":"2QV1mbbBJRGf"}},{"cell_type":"code","source":["import base64\n","\n","def get_encoded_content(location_type, location, mime_type ):\n","  \"\"\"\n","  Get the encoded content object.\n","\n","  location_type :\n","    The type of the location. ( local or GCS )\n","  location :\n","    The file location of the content.\n","  mime_type :\n","    The mime type of the content.\n","\n","  Returns:\n","    The encoded content object.\n","\n","  \"\"\"\n","\n","  content_obj = None\n","\n","  if location_type == \"local\":\n","    with open(location, 'rb') as f:\n","      raw_obj = base64.b64encode(f.read()).decode('utf-8')\n","      content_obj = Part.from_data(data=base64.b64decode(raw_obj), mime_type=mime_type)\n","\n","  elif location_type == \"GCS\":\n","        content_obj = Part.from_uri(location, mime_type=mime_type)\n","  else:\n","    raise ValueError(\"Invalid location type.\")\n","\n","  return content_obj"],"metadata":{"id":"ySzNqqGmHIBm","executionInfo":{"status":"ok","timestamp":1718194997965,"user_tz":-540,"elapsed":17,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["### Function to get the response"],"metadata":{"id":"r4NbkJ4HJYBB"}},{"cell_type":"code","source":["def generate(content_obj, query:str):\n","    \"\"\"\n","    Generate a response from the model.\n","\n","    content_obj :\n","      encoded object being analyzed in the process\n","    query :\n","      query to be sent to the model\n","\n","    Returns:\n","      The generated response.\n","\n","    \"\"\"\n","\n","    # Set model parameter : https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/send-multimodal-prompts#set_model_parameters\n","    generation_config = {\n","        \"max_output_tokens\": 8192,\n","        \"temperature\": 1,\n","        \"top_p\": 0.95,\n","    }\n","\n","    # Configure satey setting : https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes\n","    # Refer to the link to remove : https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-attributes#how_to_remove_automated_response_blocking_for_select_safety_attributes\n","    safety_settings = {\n","        generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n","        generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n","        generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n","        generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n","    }\n","\n","    responses = model.generate_content(\n","        [content_obj, query],\n","        generation_config=generation_config,\n","        safety_settings=safety_settings,\n","        stream=False,\n","    )\n","\n","    return responses.text"],"metadata":{"id":"sMaCwPVGJXX6","executionInfo":{"status":"ok","timestamp":1718194997965,"user_tz":-540,"elapsed":16,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["## Run example"],"metadata":{"id":"bGdT-2WHJuXf"}},{"cell_type":"code","source":["\n","from time import perf_counter\n","\n","t1_start = perf_counter()\n","\n","# When using local storage for the file location.\n","location_type = \"local\"\n","mime_type = \"video/mp4\"\n","\n","repository_root = \".\"\n","file_path = \"/Generative AI explained in 2 minutes.mp4\"\n","location = repository_root + file_path\n","\n","content_obj = get_encoded_content(location_type, location, mime_type )\n","\n","prompt = \"\"\"\n","You are a helpful assistant that summarizes the contents of the video.\n","1. Summarize the video contents in detail in 3 categories\n","2. Explain what's the key points of the contents\n","\"\"\"\n","\n","outcome = generate(content_obj, prompt)\n","\n","t1_end  = perf_counter()\n","print(f\"Time : {t1_end - t1_start} seconds\\n\\n\")\n","\n","display(Markdown(outcome))\n","\n","\n","# When using Google Cloud Storage for the location type.\n","\n","# location_type = \"GCS\"\n","# mime_type = \"video/mp4\"\n","# repository_root = \"gs://bucket_name\"\n","# file_path = \"/Generative AI explained in 2 minutes.mp4\"\n","# location = repository_root + file_path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":343},"id":"-0Lpj5TaJXVQ","executionInfo":{"status":"ok","timestamp":1718195021186,"user_tz":-540,"elapsed":23236,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"904818a7-cb4e-45b0-9b07-c4c2d3ec3cb9"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Time : 23.160625111999934 seconds\n","\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"The video is about Generative AI. \n\nHere's a detailed summary in 3 categories:\n\n**1. What is Generative AI?**\n   Generative AI is a type of artificial intelligence that can create new content, such as text, images, videos, music, and voices. To do this, you need to provide the AI with a description of what you want it to create. This description is called a prompt. \n\n**2. How Generative AI works**\n   Generative AI works by accessing large amounts of data, identifying patterns and similarities.  It then uses this information to create new content.  \n\n**3. Potential and challenges of Generative AI**\n   Generative AI has tremendous potential, including serving as a writing or learning partner.  It can also be misused, for example, to create deepfakes, or to generate false information.\n\n**Key points:**\n\n* Generative AI can create various new forms of content.\n* Generative AI relies on large amounts of data and prompts.\n* Generative AI has immense potential but also risks.\n* It's important to use AI tools responsibly and critically assess the output. \n"},"metadata":{}}]}]}