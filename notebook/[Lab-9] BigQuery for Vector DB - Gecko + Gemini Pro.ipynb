{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Nh--FXE-Zuf9IKz4p5puctDzIbp54bXS","timestamp":1708145654442}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Feedback to shins777@gmail.com\n","\n","이 예제는 구글의 BigQuery를 Vector database로 활용하는 예제입니다.\n","현재 상용화되거나, 오픈소스의 다양한 Vector DB가 있지만, BigQuery의 다양한 기능과, VectorDB 의 특화된 기능이 검색 성능을 높히고 효율적인 개발환경을 구성할 수 있습니다.\n","여기서 사용하는 임베딩 모델은 구글의 Gecko embedding 모듈을 사용합니다.\n","\n","이 예제는 Langchain API 기준으로 설명합니다."],"metadata":{"id":"DF_qIA8z9Ekv"}},{"cell_type":"markdown","source":["# 라이브러리 설치"],"metadata":{"id":"ITK91NvdkFY_"}},{"cell_type":"code","source":["!pip install --upgrade --quiet langchain langchain-google-vertexai google-cloud-aiplatform google-cloud-bigquery"],"metadata":{"id":"muv8WPHyhKiN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# GCP 인증 및 환경설정"],"metadata":{"id":"a2hh8J6UjnQy"}},{"cell_type":"code","source":["from google.colab import auth\n","auth.authenticate_user()"],"metadata":{"id":"tMqjhZzOlEGT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PROJECT_ID=\"ai-hangsik\"\n","REGION=\"asia-northeast3\"\n","MODEL = \"gemini-pro\"\n","\n","#set and show gcp project\n","!gcloud config set project {PROJECT_ID}\n","!gcloud config get-value project"],"metadata":{"id":"kCsSaBi7k78s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Embedding 설정 / Dataset, Table 구성\n","\n","*   https://api.python.langchain.com/en/v0.0.339/embeddings/langchain.embeddings.vertexai.VertexAIEmbeddings.html#\n","\n"],"metadata":{"id":"e4f3PisQjr2o"}},{"cell_type":"code","source":["from langchain_google_vertexai import VertexAIEmbeddings\n","\n","EBEDDING_MODEL = \"textembedding-gecko-multilingual@latest\"\n","\n","embedding = VertexAIEmbeddings(\n","    model_name=EBEDDING_MODEL, project=PROJECT_ID\n",")"],"metadata":{"id":"jCAW_z7iuzBV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.cloud import bigquery\n","\n","DATASET = \"vector_db\"\n","TABLE = \"vector_table\"\n","\n","client = bigquery.Client(project=PROJECT_ID, location=REGION)\n","client.create_dataset(dataset=DATASET, exists_ok=True)\n"],"metadata":{"id":"LoFW8KvOuy-u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","*   https://python.langchain.com/docs/integrations/vectorstores/bigquery_vector_search\n","*   https://api.python.langchain.com/en/stable/vectorstores/langchain_community.vectorstores.bigquery_vector_search.BigQueryVectorSearch.html#langchain_community.vectorstores.bigquery_vector_search.BigQueryVectorSearch\n","\n"],"metadata":{"id":"L91v8Dluw5Rj"}},{"cell_type":"code","source":["from langchain.vectorstores.utils import DistanceStrategy\n","from langchain_community.vectorstores import BigQueryVectorSearch\n","\n","table = BigQueryVectorSearch(\n","    project_id=PROJECT_ID,\n","    dataset_name=DATASET,\n","    table_name=TABLE,\n","    location=REGION,\n","    embedding=embedding,\n","\n","    #https://api.python.langchain.com/en/stable/vectorstores/langchain_community.vectorstores.utils.DistanceStrategy.html#langchain_community.vectorstores.utils.DistanceStrategy\n","    distance_strategy=DistanceStrategy.COSINE\n","\n",")"],"metadata":{"id":"82LYIoCzuy8G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Embedding 대상 Text 파일"],"metadata":{"id":"w5x1seLTlKxv"}},{"cell_type":"markdown","source":["이 텍스트 파일로 Embedding을 위한 정보를 넣어주세요."],"metadata":{"id":"HL16WgZ1lwnX"}},{"cell_type":"code","source":["import pandas as pd\n","\n","terms = pd.read_csv('./term1.csv',sep=\"|\", encoding='utf-8-sig')\n","terms"],"metadata":{"id":"Q_qjYg-3JQO_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Context 부분이 임베딩을 해야 하는 Text 또는 Paragraph 입니다."],"metadata":{"id":"qGiBxz3Ml5v4"}},{"cell_type":"code","source":["import json\n","\n","all_texts = terms['context'].to_list()\n","#metadatas = [ {'context_title': row['context_title'] } for idx, row in terms.iterrows()]\n","#table.add_texts(all_texts, metadatas=metadatas)\n","\n","table.add_texts(all_texts)"],"metadata":{"id":"Wmd7PgosMksu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Sentence similarity 데이터 조회\n","\n","\n","*   https://api.python.langchain.com/en/stable/vectorstores/langchain_community.vectorstores.bigquery_vector_search.BigQueryVectorSearch.html#langchain_community.vectorstores.bigquery_vector_search.BigQueryVectorSearch.similarity_search\n","\n"],"metadata":{"id":"tBp4Xe44plG2"}},{"cell_type":"code","source":["import time\n","s = time.time()\n","\n","query = \"질문 내용을 넣어주세요.\"\n","\n","docs = table.similarity_search(query, k=5, brute_force=True)\n","\n","for doc in docs:\n","  print(doc.page_content)\n","\n","e = time.time() - s\n","print(e)"],"metadata":{"id":"vYS-0edguy3Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Vector 형태의 쿼리 조회"],"metadata":{"id":"-GQvBIGtwNL9"}},{"cell_type":"code","source":["query_vector = embedding.embed_query(query)\n","docs = table.similarity_search_by_vector(query_vector, k=5)\n","for doc in docs:\n","  print(doc.page_content)"],"metadata":{"id":"JJeUzd0buy0Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 쿼리 유사성 다양성 최적화\n","\n","*   https://api.python.langchain.com/en/stable/vectorstores/langchain_community.vectorstores.bigquery_vector_search.BigQueryVectorSearch.html#langchain_community.vectorstores.bigquery_vector_search.BigQueryVectorSearch.max_marginal_relevance_search\n","\n"],"metadata":{"id":"8L2Z51ZCoWNS"}},{"cell_type":"code","source":["docs = table.max_marginal_relevance_search(query= query,\n","                                           k=5,\n","                                           fetch_k = 30,\n","                                           lambda_mult = 0.5,\n","                                           brute_force = True\n","                                           )\n","for doc in docs:\n","  print(doc.page_content)"],"metadata":{"id":"8AhxtDtdyKH3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Similarity with Score\n","\n","*   https://api.python.langchain.com/en/stable/vectorstores/langchain_community.vectorstores.bigquery_vector_search.BigQueryVectorSearch.html#langchain_community.vectorstores.bigquery_vector_search.BigQueryVectorSearch.similarity_search_with_relevance_scores\n","\n","\n"],"metadata":{"id":"ag7hsXPRo2fH"}},{"cell_type":"code","source":["tuples = table.similarity_search_with_relevance_scores(query, k=5)\n","\n","context ={}\n","\n","for tp in tuples:\n","    context[tp[1]] = tp[0].page_content\n","    # print(f\"==[{tp[1]}]==\")\n","    # print(tp[0].page_content)\n","\n","context"],"metadata":{"id":"LLfIdNoiUZWP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Gemini Pro 실행 - BigQuery as a Grounding Service"],"metadata":{"id":"3dCBloSvqVo-"}},{"cell_type":"markdown","source":["\n","Responsible AI setting\n","*   HarmCategory : https://cloud.google.com/vertex-ai/docs/reference/rest/v1/HarmCategory\n","*   HarmBlockThreshold : https://cloud.google.com/php/docs/reference/cloud-ai-platform/0.31.0/V1.SafetySetting.HarmBlockThreshold"],"metadata":{"id":"a8mcX8DHqdUX"}},{"cell_type":"code","source":["from langchain_google_vertexai import HarmBlockThreshold, HarmCategory\n","\n","safety_settings = {\n","                    HarmCategory.HARM_CATEGORY_UNSPECIFIED: HarmBlockThreshold.BLOCK_NONE,\n","                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n","                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n","                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n","                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE\n","}"],"metadata":{"id":"I_lsALn-UPZe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*   VertexAI API : https://api.python.langchain.com/en/stable/llms/langchain_google_vertexai.llms.VertexAI.html#langchain_google_vertexai.llms.VertexAI"],"metadata":{"id":"GpGjePxXqnW1"}},{"cell_type":"code","source":["from langchain_google_vertexai.llms import VertexAI\n","\n","gemini_pro = VertexAI( model_name = MODEL,\n","                  project=PROJECT_ID,\n","                  location=REGION,\n","                  verbose=True,\n","                  streaming=False,\n","                  safety_settings = safety_settings,\n","                  temperature = 0.2,\n","                  top_p = 1,\n","                  top_k = 40\n","                 )"],"metadata":{"id":"uub9ADukqkWj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.prompts import PromptTemplate\n","from langchain.chains import LLMChain\n","\n","query = \"질문 내용을 넣어주세요.\"\n","\n","prompt = PromptTemplate.from_template(\"\"\"\n","\n","  당신은 법률을 상담하는 AI 어시스턴트입니다.\n","  아래 Question 에 대해서 반드시 Context에 있는 개별 내용을 기반으로 단계적으로 추론해서 근거를 설명하고 답변해주세요.\n","  Context : {context}\n","  Question : {question}\n","\n","  \"\"\")\n","\n","prompt = prompt.format(context=context,\n","                       question=query)\n","\n","print(f\"Prompt : {prompt}\")\n","print(f\"답변 : {gemini_pro.invoke(prompt)}\")\n"],"metadata":{"id":"yNNnv4YXq9U2"},"execution_count":null,"outputs":[]}]}