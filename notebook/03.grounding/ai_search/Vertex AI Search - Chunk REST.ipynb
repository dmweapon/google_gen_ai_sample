{"cells":[{"cell_type":"markdown","metadata":{},"source":["Copyright 2024 shins777@gmail.com\n","\n","Licensed under the Apache License, Version 2.0 (the \"License\");\n","you may not use this file except in compliance with the License.\n","You may obtain a copy of the License at\n","\n","   https://www.apache.org/licenses/LICENSE-2.0\n","\n","Unless required by applicable law or agreed to in writing, software\n","distributed under the License is distributed on an \"AS IS\" BASIS,\n","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","See the License for the specific language governing permissions and\n","limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"oAmrBjzC-weK"},"source":["## Vertex AI Search - REST API 호출로 검색\n","\n","Feedback : shins777@gmail.com\n","\n","이 Colab 은 대부분의 고객의 요구사항이면서, 많은 유즈케이스에서의 근간이 되는 지식검색에 대한 예제입니다.\n","Gronding service 로 Vertex AI Search와 Langchain 을 연동해서 정보를 검색하고 해당 검색된 정보를 Gemini 를 통해서 추론해서 답해주는 형태의 예제입니다.\n","\n","* Vertex AI Search Manual references\n","    * https://cloud.google.com/enterprise-search?hl=ko\n","    * https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search\n","\n","\n","이 소스에서 지식 검색의 대상은 \"정보통신 진흥 및 융합 활성화 등에 관한 특별법\" 이며 해당 특별법은 아래 사이트에서 다운받았습니다.\n","https://www.law.go.kr/"]},{"cell_type":"markdown","metadata":{"id":"7QAjOW-jBnu2"},"source":["#라이브러리 설치\n","*   Langchain library : https://github.com/langchain-ai/langchain\n","*   Langchain Vertex AI API : https://api.python.langchain.com/en/stable/google_vertexai_api_reference.html\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":8892,"status":"ok","timestamp":1709842515990,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"},"user_tz":-540},"id":"SWV1C2BLrkGR"},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install --upgrade --quiet langchain langchain-core langchain-google-vertexai google-cloud-discoveryengine"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["from IPython.display import display, Markdown"]},{"cell_type":"markdown","metadata":{},"source":["### GCP 사용자 인증 / 환경설정\n","\n","GCP 인증방법은 아래와 URL 정보를 참고하여 GCP에 접근 하는 환경을 구성해야 합니다. \n","* https://cloud.google.com/docs/authentication?hl=ko\n","* 자세한 정보는 [README.md](https://github.com/shins777/google_gen_ai_sample/blob/main/notebook/gemini/README.md) 파일 참고하세요."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["#  아래 코드는 Colab 환경에서만 실행해주세요. 다른 환경에서는 동작하지 않습니다.\n","import sys\n","if \"google.colab\" in sys.modules:\n","    from google.colab import auth\n","    auth.authenticate_user()"]},{"cell_type":"markdown","metadata":{},"source":["### GCP 프로젝트 및 리전 설정\n","본인의 GCP 환경에 맞게 아래 설정을 구성하세요.  \n","* 구글의 최신버전인 gemini pro 사용을 권고드립니다.   \n","* 만일, 기본 버전 text bison 을 사용하려한다면, 참조하는 class 가 다르므로 주의하세요.  \n","* 현재 Gemini는 한국리전(asia-northeast3)을 통해서 접근이 가능합니다.\n","* 아래 SEARCH_URL Vertex AI Search를 구성 후 Integration 메뉴항목에서 추출된 값입니다. "]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1709842515990,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"},"user_tz":-540},"id":"5Pt9dV2NZtt5"},"outputs":[],"source":["PROJECT_ID=\"ai-hangsik\"\n","REGION=\"asia-northeast3\"\n","MODEL = \"gemini-1.5-pro-preview-0409\"\n","SEARCH_URL = \"https://discoveryengine.googleapis.com/v1alpha/projects/721521243942/locations/global/collections/default_collection/dataStores/it-laws-ds_1713063479348/servingConfigs/default_search:search\""]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1495,"status":"ok","timestamp":1709842517480,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"},"user_tz":-540},"id":"86-MmpChYrgD"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING: Could not open the configuration file: [/tmp/tmp.iQlNguwr1h/configurations/config_default].\n","ERROR: (gcloud.auth.print-access-token) You do not currently have an active account selected.\n","Please run:\n","\n","  $ gcloud auth login\n","\n","to obtain new credentials.\n","\n","If you have already logged in with a different account, run:\n","\n","  $ gcloud config set account ACCOUNT\n","\n","to select an already authenticated account to use.\n"]}],"source":["import vertexai\n","import google\n","import google.oauth2.credentials\n","from google.auth import compute_engine\n","import google.auth.transport.requests\n","import requests\n","import json\n","import os\n","\n","vertexai.init(project=PROJECT_ID, location=REGION)\n","\n","stream = os.popen('gcloud auth print-access-token')\n","credential_token = stream.read().strip()\n"]},{"cell_type":"markdown","metadata":{"id":"PBMhFHadc6B-"},"source":["### Vertex AI Search 검색"]},{"cell_type":"markdown","metadata":{"id":"i2kJC01pivQc"},"source":["아래 코드는 REST API를 통해서 Verext AI Search에 직접 검색 쿼리를 보내는 예제입니다.\n","검색에 활용되는 패러미터는 ContentSearchSpec 에 따릅니다. 아래 정보 참고하세요.\n","* https://cloud.google.com/python/docs/reference/discoveryengine/latest/google.cloud.discoveryengine_v1beta.types.SearchRequest.ContentSearchSpec\n","\n","특히 ExtractiveContentSpec은 검색 컨텐츠를 좀더 상세하게 얻을수 있는 설정입니다. 아래 정보 참고하세요.\n","* https://cloud.google.com/python/docs/reference/discoveryengine/latest/google.cloud.discoveryengine_v1beta.types.SearchRequest.ContentSearchSpec.ExtractiveContentSpec"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1709842517480,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"},"user_tz":-540},"id":"cjEpooaAYc2N"},"outputs":[],"source":["def retrieve_vertex_ai_search(question:str, search_url:str, page_size:int)->str:\n","\n","  \"\"\" retrieve information from enterprise search ( discovery engine )\"\"\"\n","\n","  # Create a credentials token to call a REST API\n","  headers = {\n","      \"Authorization\": \"Bearer \"+ credential_token,\n","      \"Content-Type\": \"application/json\"\n","  }\n","\n","  query_dic ={\n","      \"query\": question,\n","      \"page_size\": str(page_size),\n","      \"offset\": 0,\n","      \"contentSearchSpec\":{\n","\n","            \"searchResultMode\" : \"CHUNKS\",\n","            \"chunkSpec\" : {\n","                \"numPreviousChunks\" : 2,\n","                \"numNextChunks\" : 2\n","            }              \n","      },\n","  }\n","\n","  data = json.dumps(query_dic)\n","\n","  # Encode data as UTF8\n","  data=data.encode(\"utf8\")\n","\n","  response = requests.post(search_url,headers=headers, data=data)\n","\n","  print(response.text)\n","  return response.text\n"]},{"cell_type":"markdown","metadata":{"id":"Hq8DNhbnjch-"},"source":["#### Search 결과 파싱 로직\n","아래 로직은 검색된 결과를 파싱하는 로직입니다."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":498,"status":"ok","timestamp":1709842517975,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"},"user_tz":-540},"id":"zfThGqgSYhjy"},"outputs":[],"source":["def parse_chunks(response_text:str)->dict:\n","\n","    \"\"\"Parse response to build a conext to be sent to LLM\"\"\"\n","\n","    dict_results = json.loads(response_text)\n","\n","    index = 0\n","    search_results = {}\n","\n","    if dict_results.get('results'):\n","\n","        for result in dict_results['results']:\n","\n","            item = {}\n","\n","            chunk = result['chunk']\n","\n","            #print(chunk)\n","            # print(f\"content {chunk['content']}\")\n","\n","            # print(f\"documentMetadata {chunk['documentMetadata']}\")\n","            # print(f\"documentMetadata {chunk['documentMetadata']['title']}\")\n","            # print(f\"documentMetadata {chunk['documentMetadata']['uri']}\")\n","\n","            # print(f\"documentMetadata {chunk['pageSpan']['pageStart']}\")\n","            # print(f\"documentMetadata {chunk['pageSpan']['pageEnd']}\")\n","\n","            # print(f\"previousChunks {chunk['chunkMetadata']['previousChunks'][0]['content']}\")\n","            # print(f\"nextChunks {chunk['chunkMetadata']['nextChunks'][0]['content']}\")\n","\n","            item['title'] = chunk['documentMetadata']['title']\n","            item['uri'] = chunk['documentMetadata']['uri']\n","            item['pageSpan'] = f\"{chunk['pageSpan']['pageStart']} ~ {chunk['pageSpan']['pageEnd']}\"\n","            item['content'] = chunk['content']\n","\n","            # chunk 는 현재 Contents에 가까운것 부터 나타남.\n","            p_chunks = chunk['chunkMetadata']['previousChunks']\n","            for p_chunk in p_chunks:\n","                item['content'] = p_chunk['content'] +\"\\n\"+ item['content']\n","\n","            n_chunks = chunk['chunkMetadata']['nextChunks']\n","            for n_chunk in n_chunks:\n","                item['content'] = item['content'] +\"\\n\"+ n_chunk['content']\n","\n","            search_results[f'results-{index}'] = item\n","            index = index+1\n","\n","    return search_results"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1709842517975,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"},"user_tz":-540},"id":"xUKSEYW2Yhhb","outputId":"eb7e232d-d882-41ec-c30b-02d703ad9463"},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"error\": {\n","    \"code\": 401,\n","    \"message\": \"Request is missing required authentication credential. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project.\",\n","    \"status\": \"UNAUTHENTICATED\",\n","    \"details\": [\n","      {\n","        \"@type\": \"type.googleapis.com/google.rpc.ErrorInfo\",\n","        \"reason\": \"CREDENTIALS_MISSING\",\n","        \"domain\": \"googleapis.com\",\n","        \"metadata\": {\n","          \"method\": \"google.cloud.discoveryengine.v1alpha.SearchService.Search\",\n","          \"service\": \"discoveryengine.googleapis.com\"\n","        }\n","      }\n","    ]\n","  }\n","}\n","\n"]}],"source":["question = \"개인정보 보호법에 대해서 설명해주세요.\"\n","\n","page_size = 2\n","\n","searched_ctx = retrieve_vertex_ai_search(question, SEARCH_URL, page_size)\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{}\n"]}],"source":["context = parse_chunks(searched_ctx)\n","\n","print(context)"]},{"cell_type":"markdown","metadata":{"id":"xhTozAE9GEua"},"source":["### Gemini Pro 실행 - Vertex AI Search as a Grounding Service"]},{"cell_type":"markdown","metadata":{"id":"62QIONAYMNR5"},"source":["*   VertexAI API : https://api.python.langchain.com/en/stable/llms/langchain_google_vertexai.llms.VertexAI.html#langchain_google_vertexai.llms.VertexAI"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1709842517975,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"},"user_tz":-540},"id":"TqCRrsX9R1qv"},"outputs":[],"source":["from langchain_google_vertexai.llms import VertexAI\n","\n","gemini_pro = VertexAI( model_name = MODEL,\n","                  project=PROJECT_ID,\n","                  location=REGION,\n","                  verbose=True,\n","                  streaming=False,\n","                  temperature = 0.2,\n","                  top_p = 1,\n","                  top_k = 40\n","                 )"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4693,"status":"ok","timestamp":1709842522666,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"},"user_tz":-540},"id":"dAFajcCxZRNd","outputId":"7408eba0-2067-4a8f-bd04-daff80886ef7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Prompt : \n","\n","  당신은 법률을 상담해주는 AI 어시스턴트입니다.\n","  아래 Question 에 대해서 반드시 Context에 있는 개별 내용을 기반으로 단계적으로 추론해서 근거를 설명하고 답변해주세요.\n","  Context : {}\n","  Question : 개인정보 보호법에 대해서 설명해주세요.\n","\n","  \n"]},{"name":"stderr","output_type":"stream","text":["Retrying langchain_google_vertexai.llms._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ServiceUnavailable: 503 Getting metadata from plugin failed with error: string indices must be integers.\n","Retrying langchain_google_vertexai.llms._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ServiceUnavailable: 503 Getting metadata from plugin failed with error: string indices must be integers.\n","Retrying langchain_google_vertexai.llms._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ServiceUnavailable: 503 Getting metadata from plugin failed with error: string indices must be integers.\n","Retrying langchain_google_vertexai.llms._completion_with_retry.<locals>._completion_with_retry_inner in 8.0 seconds as it raised ServiceUnavailable: 503 Getting metadata from plugin failed with error: string indices must be integers.\n","Retrying langchain_google_vertexai.llms._completion_with_retry.<locals>._completion_with_retry_inner in 10.0 seconds as it raised ServiceUnavailable: 503 Getting metadata from plugin failed with error: string indices must be integers.\n"]},{"ename":"ServiceUnavailable","evalue":"503 Getting metadata from plugin failed with error: string indices must be integers","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py:1176\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1170\u001b[0m (\n\u001b[1;32m   1171\u001b[0m     state,\n\u001b[1;32m   1172\u001b[0m     call,\n\u001b[1;32m   1173\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blocking(\n\u001b[1;32m   1174\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1175\u001b[0m )\n\u001b[0;32m-> 1176\u001b[0m \u001b[39mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/grpc/_channel.py:1005\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1005\u001b[0m     \u001b[39mraise\u001b[39;00m _InactiveRpcError(state)\n","\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"Getting metadata from plugin failed with error: string indices must be integers\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"Getting metadata from plugin failed with error: string indices must be integers\", grpc_status:14, created_time:\"2024-04-25T00:02:27.224688877+00:00\"}\"\n>","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mServiceUnavailable\u001b[0m                        Traceback (most recent call last)","\u001b[1;32m/home/admin_/google_gen_ai_sample/notebook/03.grounding/ai_search/Vertex AI Search - Chunk REST.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://970-cs-1000207905015-default.cs-asia-east1-jnrc.cloudshell.dev/home/admin_/google_gen_ai_sample/notebook/03.grounding/ai_search/Vertex%20AI%20Search%20-%20Chunk%20REST.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m prompt \u001b[39m=\u001b[39m prompt\u001b[39m.\u001b[39mformat(context\u001b[39m=\u001b[39mcontext,\n\u001b[1;32m     <a href='vscode-notebook-cell://970-cs-1000207905015-default.cs-asia-east1-jnrc.cloudshell.dev/home/admin_/google_gen_ai_sample/notebook/03.grounding/ai_search/Vertex%20AI%20Search%20-%20Chunk%20REST.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m                        question\u001b[39m=\u001b[39mquestion)\n\u001b[1;32m     <a href='vscode-notebook-cell://970-cs-1000207905015-default.cs-asia-east1-jnrc.cloudshell.dev/home/admin_/google_gen_ai_sample/notebook/03.grounding/ai_search/Vertex%20AI%20Search%20-%20Chunk%20REST.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPrompt : \u001b[39m\u001b[39m{\u001b[39;00mprompt\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://970-cs-1000207905015-default.cs-asia-east1-jnrc.cloudshell.dev/home/admin_/google_gen_ai_sample/notebook/03.grounding/ai_search/Vertex%20AI%20Search%20-%20Chunk%20REST.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m response \u001b[39m=\u001b[39m gemini_pro\u001b[39m.\u001b[39;49minvoke(prompt)\n\u001b[1;32m     <a href='vscode-notebook-cell://970-cs-1000207905015-default.cs-asia-east1-jnrc.cloudshell.dev/home/admin_/google_gen_ai_sample/notebook/03.grounding/ai_search/Vertex%20AI%20Search%20-%20Chunk%20REST.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m display(Markdown(response))\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/language_models/llms.py:276\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\n\u001b[1;32m    267\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    268\u001b[0m     \u001b[39minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    273\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    274\u001b[0m     config \u001b[39m=\u001b[39m ensure_config(config)\n\u001b[1;32m    275\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 276\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m    277\u001b[0m             [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_input(\u001b[39minput\u001b[39;49m)],\n\u001b[1;32m    278\u001b[0m             stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    279\u001b[0m             callbacks\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcallbacks\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    280\u001b[0m             tags\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtags\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    281\u001b[0m             metadata\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    282\u001b[0m             run_name\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mrun_name\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    283\u001b[0m             run_id\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mrun_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    284\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    285\u001b[0m         )\n\u001b[1;32m    286\u001b[0m         \u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m    287\u001b[0m         \u001b[39m.\u001b[39mtext\n\u001b[1;32m    288\u001b[0m     )\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/language_models/llms.py:633\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    626\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    627\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    631\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    632\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 633\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/language_models/llms.py:803\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m get_llm_cache() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    789\u001b[0m     run_managers \u001b[39m=\u001b[39m [\n\u001b[1;32m    790\u001b[0m         callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m    791\u001b[0m             dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    801\u001b[0m         )\n\u001b[1;32m    802\u001b[0m     ]\n\u001b[0;32m--> 803\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_helper(\n\u001b[1;32m    804\u001b[0m         prompts, stop, run_managers, \u001b[39mbool\u001b[39;49m(new_arg_supported), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    805\u001b[0m     )\n\u001b[1;32m    806\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[1;32m    807\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_prompts) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/language_models/llms.py:670\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n\u001b[1;32m    669\u001b[0m         run_manager\u001b[39m.\u001b[39mon_llm_error(e, response\u001b[39m=\u001b[39mLLMResult(generations\u001b[39m=\u001b[39m[]))\n\u001b[0;32m--> 670\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    671\u001b[0m flattened_outputs \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m    672\u001b[0m \u001b[39mfor\u001b[39;00m manager, flattened_output \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(run_managers, flattened_outputs):\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/language_models/llms.py:657\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_generate_helper\u001b[39m(\n\u001b[1;32m    648\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    649\u001b[0m     prompts: List[\u001b[39mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    654\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    655\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    656\u001b[0m         output \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 657\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    658\u001b[0m                 prompts,\n\u001b[1;32m    659\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    660\u001b[0m                 \u001b[39m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    661\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    662\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    663\u001b[0m             )\n\u001b[1;32m    664\u001b[0m             \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    665\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[1;32m    666\u001b[0m         )\n\u001b[1;32m    667\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    668\u001b[0m         \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_google_vertexai/llms.py:223\u001b[0m, in \u001b[0;36mVertexAI._generate\u001b[0;34m(self, prompts, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m     generations\u001b[39m.\u001b[39mappend([generation])\n\u001b[1;32m    222\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m     res \u001b[39m=\u001b[39m _completion_with_retry(\n\u001b[1;32m    224\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    225\u001b[0m         [prompt],\n\u001b[1;32m    226\u001b[0m         stream\u001b[39m=\u001b[39;49mshould_stream,\n\u001b[1;32m    227\u001b[0m         is_gemini\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_is_gemini_model,\n\u001b[1;32m    228\u001b[0m         run_manager\u001b[39m=\u001b[39;49mrun_manager,\n\u001b[1;32m    229\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams,\n\u001b[1;32m    230\u001b[0m     )\n\u001b[1;32m    231\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_gemini_model:\n\u001b[1;32m    232\u001b[0m         usage_metadata \u001b[39m=\u001b[39m res\u001b[39m.\u001b[39mto_dict()\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39musage_metadata\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_google_vertexai/llms.py:73\u001b[0m, in \u001b[0;36m_completion_with_retry\u001b[0;34m(llm, prompt, stream, is_gemini, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mpredict(prompt[\u001b[39m0\u001b[39m], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     72\u001b[0m \u001b[39mwith\u001b[39;00m telemetry\u001b[39m.\u001b[39mtool_context_manager(llm\u001b[39m.\u001b[39m_user_agent):\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m _completion_with_retry_inner(prompt, is_gemini, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tenacity/__init__.py:325\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    323\u001b[0m     retry_exc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[0;32m--> 325\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m    326\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[1;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tenacity/__init__.py:158\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreraise\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mNoReturn:\n\u001b[1;32m    157\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_attempt\u001b[39m.\u001b[39mfailed:\n\u001b[0;32m--> 158\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlast_attempt\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    159\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\n","File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n","File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_google_vertexai/llms.py:61\u001b[0m, in \u001b[0;36m_completion_with_retry.<locals>._completion_with_retry_inner\u001b[0;34m(prompt, is_gemini, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry_inner\u001b[39m(\n\u001b[1;32m     58\u001b[0m     prompt: List[Union[\u001b[39mstr\u001b[39m, Image]], is_gemini: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any\n\u001b[1;32m     59\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m     60\u001b[0m     \u001b[39mif\u001b[39;00m is_gemini:\n\u001b[0;32m---> 61\u001b[0m         \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mgenerate_content(\n\u001b[1;32m     62\u001b[0m             prompt,\n\u001b[1;32m     63\u001b[0m             stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m     64\u001b[0m             safety_settings\u001b[39m=\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39msafety_settings\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m     65\u001b[0m             generation_config\u001b[39m=\u001b[39;49mkwargs,\n\u001b[1;32m     66\u001b[0m         )\n\u001b[1;32m     67\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m         \u001b[39mif\u001b[39;00m stream:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/vertexai/generative_models/_generative_models.py:405\u001b[0m, in \u001b[0;36m_GenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, stream)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_content_streaming(\n\u001b[1;32m    398\u001b[0m         contents\u001b[39m=\u001b[39mcontents,\n\u001b[1;32m    399\u001b[0m         generation_config\u001b[39m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    402\u001b[0m         tool_config\u001b[39m=\u001b[39mtool_config,\n\u001b[1;32m    403\u001b[0m     )\n\u001b[1;32m    404\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_content(\n\u001b[1;32m    406\u001b[0m         contents\u001b[39m=\u001b[39;49mcontents,\n\u001b[1;32m    407\u001b[0m         generation_config\u001b[39m=\u001b[39;49mgeneration_config,\n\u001b[1;32m    408\u001b[0m         safety_settings\u001b[39m=\u001b[39;49msafety_settings,\n\u001b[1;32m    409\u001b[0m         tools\u001b[39m=\u001b[39;49mtools,\n\u001b[1;32m    410\u001b[0m         tool_config\u001b[39m=\u001b[39;49mtool_config,\n\u001b[1;32m    411\u001b[0m     )\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/vertexai/generative_models/_generative_models.py:494\u001b[0m, in \u001b[0;36m_GenerativeModel._generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generates content.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \n\u001b[1;32m    471\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39m    A single GenerationResponse object\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    487\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_request(\n\u001b[1;32m    488\u001b[0m     contents\u001b[39m=\u001b[39mcontents,\n\u001b[1;32m    489\u001b[0m     generation_config\u001b[39m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    492\u001b[0m     tool_config\u001b[39m=\u001b[39mtool_config,\n\u001b[1;32m    493\u001b[0m )\n\u001b[0;32m--> 494\u001b[0m gapic_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prediction_client\u001b[39m.\u001b[39;49mgenerate_content(request\u001b[39m=\u001b[39;49mrequest)\n\u001b[1;32m    495\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_response(gapic_response)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/aiplatform_v1beta1/services/prediction_service/client.py:2102\u001b[0m, in \u001b[0;36mPredictionServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2099\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   2101\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 2102\u001b[0m response \u001b[39m=\u001b[39m rpc(\n\u001b[1;32m   2103\u001b[0m     request,\n\u001b[1;32m   2104\u001b[0m     retry\u001b[39m=\u001b[39;49mretry,\n\u001b[1;32m   2105\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m   2106\u001b[0m     metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[1;32m   2107\u001b[0m )\n\u001b[1;32m   2109\u001b[0m \u001b[39m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   2110\u001b[0m \u001b[39mreturn\u001b[39;00m response\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compression \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mfrom_grpc_error(exc) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n","\u001b[0;31mServiceUnavailable\u001b[0m: 503 Getting metadata from plugin failed with error: string indices must be integers"]}],"source":["from langchain.prompts import PromptTemplate\n","from langchain.chains import LLMChain\n","\n","\n","\n","prompt = PromptTemplate.from_template(\"\"\"\n","\n","  당신은 법률을 상담해주는 AI 어시스턴트입니다.\n","  아래 Question 에 대해서 반드시 Context에 있는 개별 내용을 기반으로 단계적으로 추론해서 근거를 설명하고 답변해주세요.\n","  Context : {context}\n","  Question : {question}\n","\n","  \"\"\")\n","\n","prompt = prompt.format(context=context,\n","                       question=question)\n","\n","print(f\"Prompt : {prompt}\")\n","\n","response = gemini_pro.invoke(prompt)\n","display(Markdown(response))"]}],"metadata":{"colab":{"provenance":[{"file_id":"1Y8uUsQxEa1wM_0LFkGQ33HhiJzTqP44N","timestamp":1707916522452},{"file_id":"1ysth26WNEZ89ceoUWyiBNEhJhAKPzZzD","timestamp":1707791310414},{"file_id":"1SMBsO1Oo1C_iwdVlaPxa-nHarsr1LlXw","timestamp":1707790104224},{"file_id":"12QOQwx4nCfn-TVBJz482kmzE9AO7LOEa","timestamp":1706083956041},{"file_id":"1SEMv5rLuJzrFmgv6ijM-a6frQK6vJh-F","timestamp":1685622927692},{"file_id":"17KvSE1Jozr-l8MPgV0qc96RqjDGib6EG","timestamp":1683740067510},{"file_id":"/v2/external/notebooks/snippets/bigquery.ipynb","timestamp":1674946081821}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
